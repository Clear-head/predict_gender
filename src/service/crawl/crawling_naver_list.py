"""
ë„¤ì´ë²„ ì§€ë„ ì¦ê²¨ì°¾ê¸° ëª©ë¡ í¬ë¡¤ë§ ëª¨ë“ˆ (ë©”ëª¨ë¦¬ ìµœì í™” + ë´‡ ìš°íšŒ + ë³‘ë ¬ ì²˜ë¦¬)
ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¬ìƒì„±í•˜ì—¬ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
"""
import asyncio
from playwright.async_api import async_playwright, TimeoutError, Page
import sys, os
from dotenv import load_dotenv

load_dotenv(dotenv_path="src/.env")

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from src.logger.custom_logger import get_logger

# ê³µí†µ ëª¨ë“ˆ import
from src.service.crawl.utils.optimized_browser_manager import OptimizedBrowserManager
from src.service.crawl.utils.human_like_actions import HumanLikeActions
from src.service.crawl.utils.scroll_helper import FavoriteListScroller
from src.service.crawl.utils.store_detail_extractor import StoreDetailExtractor
from src.service.crawl.utils.store_data_saver import StoreDataSaver
from src.service.crawl.utils.crawling_manager import CrawlingManager


class NaverMapFavoriteCrawler:
    """ë„¤ì´ë²„ ì§€ë„ ì¦ê²¨ì°¾ê¸° ëª©ë¡ í¬ë¡¤ë§ í´ë˜ìŠ¤ (ë©”ëª¨ë¦¬ ìµœì í™” + ë³‘ë ¬ ì²˜ë¦¬)"""
    
    RESTART_INTERVAL = 30  # 30ê°œë§ˆë‹¤ ì»¨í…ìŠ¤íŠ¸ ì¬ì‹œì‘
    
    def __init__(self, headless: bool = False):
        self.logger = get_logger(__name__)
        self.headless = headless
        self.data_saver = StoreDataSaver()
        self.human_actions = HumanLikeActions()
        self.success_count = 0
        self.fail_count = 0
    
    async def crawl_favorite_list(self, favorite_url: str, delay: int = 20):
        """
        ë„¤ì´ë²„ ì§€ë„ ì¦ê²¨ì°¾ê¸° ëª©ë¡ì—ì„œ ì¥ì†Œë“¤ì„ ë³‘ë ¬ í¬ë¡¤ë§
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¬ìƒì„±í•˜ì—¬ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
        
        Args:
            favorite_url: ì¦ê²¨ì°¾ê¸° URL
            delay: ê° ì¥ì†Œ í¬ë¡¤ë§ ì‚¬ì´ì˜ ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
        """
        async with async_playwright() as p:
            browser = await OptimizedBrowserManager.create_optimized_browser(p, self.headless)
            
            try:
                # 1ë‹¨ê³„: ì „ì²´ ì¥ì†Œ ê°œìˆ˜ íŒŒì•…
                total = await self._get_total_place_count(browser, favorite_url)
                
                if total == 0:
                    self.logger.warning("í¬ë¡¤ë§í•  ì¥ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                self.logger.info(f"ì´ {total}ê°œ ì¥ì†Œ í¬ë¡¤ë§ ì‹œì‘ (ë³‘ë ¬ ì²˜ë¦¬)")
                self.logger.info(f"ë°°ì¹˜ í¬ê¸°: {self.RESTART_INTERVAL}ê°œ")
                self.logger.info(f"ì˜ˆìƒ ë°°ì¹˜ ìˆ˜: {(total + self.RESTART_INTERVAL - 1) // self.RESTART_INTERVAL}ê°œ")
                
                # 2ë‹¨ê³„: ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë³‘ë ¬ í¬ë¡¤ë§
                for batch_start in range(0, total, self.RESTART_INTERVAL):
                    batch_end = min(batch_start + self.RESTART_INTERVAL, total)
                    batch_num = batch_start // self.RESTART_INTERVAL + 1
                    total_batches = (total + self.RESTART_INTERVAL - 1) // self.RESTART_INTERVAL
                    
                    self.logger.info(f"ë°°ì¹˜ {batch_num}/{total_batches}: {batch_start+1}~{batch_end}/{total} ì²˜ë¦¬ ì‹œì‘")
                    
                    # ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                    context = await OptimizedBrowserManager.create_stealth_context(browser)
                    page = await context.new_page()
                    
                    try:
                        # ë°°ì¹˜ ë³‘ë ¬ í¬ë¡¤ë§ ì‹¤í–‰
                        await self._process_batch_parallel(
                            page, favorite_url, 
                            batch_start, batch_end, total, delay
                        )
                        
                    except Exception as e:
                        self.logger.error(f"ë°°ì¹˜ {batch_start+1}~{batch_end} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        import traceback
                        self.logger.error(traceback.format_exc())
                    finally:
                        await context.close()
                        await asyncio.sleep(3)
                        
                        # ë°°ì¹˜ ê°„ ê¸´ íœ´ì‹
                        if batch_end < total:
                            import random
                            rest_time = random.uniform(20, 40)
                            self.logger.info(f"ë°°ì¹˜ {batch_num} ì™„ë£Œ! {rest_time:.0f}ì´ˆ íœ´ì‹ í›„ ë‹¤ìŒ ë°°ì¹˜ ì‹œì‘...\n")
                            await asyncio.sleep(rest_time)
                
                # 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ì¶œë ¥
                self.logger.info(f"ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ!")
                self.logger.info(f"ì´ ì²˜ë¦¬: {total}ê°œ")
                self.logger.info(f"ì„±ê³µ: {self.success_count}ê°œ")
                self.logger.info(f"ì‹¤íŒ¨: {self.fail_count}ê°œ")
                if total > 0:
                    self.logger.info(f"ì„±ê³µë¥ : {self.success_count/total*100:.1f}%")
                
            except Exception as e:
                self.logger.error(f"í¬ë¡¤ë§ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
                import traceback
                self.logger.error(traceback.format_exc())
            finally:
                await browser.close()
    
    async def _get_total_place_count(self, browser, favorite_url: str) -> int:
        """ì „ì²´ ì¥ì†Œ ê°œìˆ˜ë§Œ ë¹ ë¥´ê²Œ íŒŒì•…"""
        context = await browser.new_context()
        page = await context.new_page()
        
        try:
            self.logger.info("ì „ì²´ ì¥ì†Œ ê°œìˆ˜ í™•ì¸ ì¤‘...")
            
            await page.goto(favorite_url, wait_until='domcontentloaded', timeout=60000)
            await asyncio.sleep(10)
            
            list_frame_locator = page.frame_locator('iframe#myPlaceBookmarkListIframe')
            list_frame = page.frame('myPlaceBookmarkListIframe')
            
            if not list_frame:
                self.logger.error("myPlaceBookmarkListIframeì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return 0
            
            await asyncio.sleep(3)
            
            place_selector = await self._find_place_selector(list_frame_locator, list_frame)
            if not place_selector:
                return 0
            
            # ìŠ¤í¬ë¡¤í•˜ì—¬ ì „ì²´ ë¡œë“œ
            count = await FavoriteListScroller.scroll_to_load_all(
                frame_locator=list_frame_locator,
                item_selector=place_selector
            )
            
            self.logger.info(f"ì´ {count}ê°œ ì¥ì†Œ í™•ì¸ ì™„ë£Œ\n")
            
            return count
            
        except Exception as e:
            self.logger.error(f"ì „ì²´ ê°œìˆ˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return 0
        finally:
            await context.close()
    
    async def _process_batch_parallel(
        self, 
        page: Page, 
        favorite_url: str,
        batch_start: int, 
        batch_end: int, 
        total: int, 
        delay: int
    ):
        """
        ë°°ì¹˜ ë‹¨ìœ„ ë³‘ë ¬ í¬ë¡¤ë§
        
        Args:
            page: Playwright Page ê°ì²´
            favorite_url: ì¦ê²¨ì°¾ê¸° URL
            batch_start: ë°°ì¹˜ ì‹œì‘ ì¸ë±ìŠ¤
            batch_end: ë°°ì¹˜ ì¢…ë£Œ ì¸ë±ìŠ¤
            total: ì „ì²´ ì¥ì†Œ ìˆ˜
            delay: ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„
        """
        try:
            # í˜ì´ì§€ ë¡œë“œ ë° iframe ì„¤ì •
            self.logger.debug("ì¦ê²¨ì°¾ê¸° í˜ì´ì§€ ë¡œë“œ ì¤‘...")
            await page.goto(favorite_url, wait_until='domcontentloaded', timeout=60000)
            await asyncio.sleep(10)
            
            await page.wait_for_selector('iframe#myPlaceBookmarkListIframe', timeout=30000)
            list_frame_locator = page.frame_locator('iframe#myPlaceBookmarkListIframe')
            list_frame = page.frame('myPlaceBookmarkListIframe')
            
            if not list_frame:
                self.logger.error("myPlaceBookmarkListIframeì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            await asyncio.sleep(3)
            
            place_selector = await self._find_place_selector(list_frame_locator, list_frame)
            if not place_selector:
                self.logger.error("ì¥ì†Œ ì„ íƒìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # batch_endê¹Œì§€ ìŠ¤í¬ë¡¤
            await FavoriteListScroller.scroll_to_index(
                frame_locator=list_frame_locator,
                item_selector=place_selector,
                target_index=batch_end
            )
            
            # ========================================
            # ğŸ”¥ ë³‘ë ¬ ì²˜ë¦¬: CrawlingManager ì‚¬ìš©
            # ========================================
            batch_items = list(range(batch_start, batch_end))
            
            crawling_manager = CrawlingManager("ì¦ê²¨ì°¾ê¸°")
            
            await crawling_manager.execute_crawling_with_save(
                stores=batch_items,
                crawl_func=lambda idx, i, t: self._crawl_single_place_parallel(
                    page, list_frame_locator, place_selector, idx, total
                ),
                save_func=self._save_wrapper,
                delay=delay
            )
            
            # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            self.success_count += crawling_manager.success_count
            self.fail_count += crawling_manager.fail_count
            
            batch_num = batch_start // self.RESTART_INTERVAL + 1
            self.logger.info(f"ë°°ì¹˜ {batch_num} ({batch_start+1}~{batch_end}) ì™„ë£Œ!")
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
    
    async def _crawl_single_place_parallel(
        self,
        page: Page,
        list_frame_locator,
        place_selector: str,
        idx: int,
        total: int
    ):
        """
        ë‹¨ì¼ ì¥ì†Œ í¬ë¡¤ë§ (ë³‘ë ¬ìš©)
        
        Returns:
            Tuple: (store_data, place_name) ë˜ëŠ” None
        """
        try:
            # ë§¤ë²ˆ ëª©ë¡ ìƒˆë¡œ ê°€ì ¸ì˜¤ê¸°
            places = await list_frame_locator.locator(place_selector).all()
            
            if idx >= len(places):
                self.logger.error(f"ì¸ë±ìŠ¤ ë²”ìœ„ ì´ˆê³¼: {idx}/{len(places)}")
                return None
            
            place = places[idx]
            place_name = await self._extract_place_name(place, idx)
            
            # ì‚¬ëŒì²˜ëŸ¼ í´ë¦­
            await self.human_actions.human_like_click(place)
            await asyncio.sleep(3)
            
            # íì—… íŒì—… ì²´í¬
            if await self._check_and_close_popup(list_frame_locator, place_name):
                self.logger.warning(f"'{place_name}' íì—… ë˜ëŠ” ì ‘ê·¼ ë¶ˆê°€")
                return None
            
            # entry iframe
            entry_frame = await self._get_entry_frame(page)
            if not entry_frame:
                self.logger.error(f"'{place_name}' entry iframe ì—†ìŒ")
                return None
            
            # ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            extractor = StoreDetailExtractor(entry_frame, page)
            store_data = await extractor.extract_all_details()
            
            if store_data:
                # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
                await OptimizedBrowserManager.clear_page_resources(page)
                return (store_data, place_name)
            else:
                self.logger.error(f"'{place_name}' ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨")
                return None
                
        except Exception as e:
            self.logger.error(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    async def _save_wrapper(self, idx: int, total: int, store_data_tuple, place_name: str):
        """
        ì €ì¥ ë˜í¼ (CrawlingManagerìš©)
        
        Args:
            store_data_tuple: (store_data, place_name) íŠœí”Œ ë˜ëŠ” None
        """
        if store_data_tuple is None:
            return (False, "í¬ë¡¤ë§ ì‹¤íŒ¨")
        
        store_data, actual_name = store_data_tuple
        
        return await self.data_saver.save_store_data(
            idx=idx,
            total=total,
            store_data=store_data,
            store_name=actual_name,
            log_prefix="ì¦ê²¨ì°¾ê¸°"
        )
    
    async def _find_place_selector(self, list_frame_locator, list_frame):
        """ì¥ì†Œ ì„ íƒì ì°¾ê¸°"""
        possible_selectors = [
            '#app > div > div:nth-child(3) > div > ul > li',
            'ul.list_place > li',
            'ul > li',
            '[role="list"] > *',
        ]
        
        for selector in possible_selectors:
            try:
                elements = await list_frame_locator.locator(selector).all()
                if len(elements) > 0:
                    self.logger.debug(f"ì„ íƒì ë°œê²¬: {selector}")
                    return selector
            except:
                continue
        
        self.logger.error("ì¥ì†Œ ëª©ë¡ ì„ íƒìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    async def _extract_place_name(self, place, idx: int) -> str:
        """ì¥ì†Œëª… ì¶”ì¶œ"""
        try:
            name_selectors = ['div.name', 'span.name', '.place_name', 'a.name', '.item_name', 'span']
            
            for name_sel in name_selectors:
                try:
                    place_name = await place.locator(name_sel).first.inner_text(timeout=2000)
                    if place_name and place_name.strip():
                        return place_name.strip()
                except:
                    continue
            
            return f"ì¥ì†Œ {idx+1}"
        except:
            return f"ì¥ì†Œ {idx+1}"
    
    async def _check_and_close_popup(self, list_frame_locator, place_name: str) -> bool:
        """íì—… íŒì—… ì²´í¬ ë° ë‹«ê¸°"""
        popup_selectors = [
            'body > div:nth-child(4) > div._show_62e0u_8',
            'div._show_62e0u_8',
            'div._popup_62e0u_1._show_62e0u_8',
            'div[class*="_show_"]',
            'div._popup_62e0u_1',
        ]
        
        is_popup_found = False
        
        for popup_selector in popup_selectors:
            try:
                popup_element = list_frame_locator.locator(popup_selector).first
                is_visible = await popup_element.is_visible(timeout=1000)
                
                if is_visible:
                    is_popup_found = True
                    break
            except:
                continue
        
        if is_popup_found:
            button_selectors = [
                'body > div:nth-child(4) > div > div._popup_62e0u_1._at_pc_62e0u_21._show_62e0u_8 > div._popup_buttons_62e0u_85 > button',
                'div._popup_buttons_62e0u_85 > button',
            ]
            
            for button_selector in button_selectors:
                try:
                    popup_button = list_frame_locator.locator(button_selector).first
                    if await popup_button.is_visible(timeout=1000):
                        await popup_button.click(timeout=2000)
                        await asyncio.sleep(0.5)
                        break
                except:
                    continue
        
        return is_popup_found
    
    async def _get_entry_frame(self, page: Page):
        """ìƒì„¸ ì •ë³´ iframe ê°€ì ¸ì˜¤ê¸°"""
        try:
            await page.wait_for_selector('iframe#entryIframe', timeout=10000)
            entry_frame = page.frame_locator('iframe#entryIframe')
            await asyncio.sleep(3)
            return entry_frame
        except TimeoutError:
            return None


async def main(favorite_url='https://map.naver.com/p/favorite/YOUR_URL'):
    """ë©”ì¸ í•¨ìˆ˜"""
    logger = get_logger(__name__)
    

    logger.info("ë„¤ì´ë²„ ì§€ë„ ì¦ê²¨ì°¾ê¸° í¬ë¡¤ëŸ¬ ì‹œì‘ (ë³‘ë ¬ ì²˜ë¦¬)")

    
    crawler = NaverMapFavoriteCrawler(headless=False)
    
    await crawler.crawl_favorite_list(
        favorite_url=favorite_url,
        delay=15
    )
    

    logger.info("í¬ë¡¤ëŸ¬ ì¢…ë£Œ")